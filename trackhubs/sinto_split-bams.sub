#!/bin/bash
#SBATCH --job-name=sinto
#SBATCH -p standard
#SBATCH -A vswarup_lab
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=32
#SBATCH --error=slurm-%J.err
#SBATCH --mem 64G
#SBATCH --array=0-38
#SBATCH --time=4:00:00

# activate conda env with sinto + deeptools installed
source ~/.bashrc
conda activate scvi-env
module load samtools

# directory with barcodes files:
barcodes_dir="/dfs7/swaruplab/smorabit/collab/woodlab/cocaine_mouse_2021/Nurr2c_vs_GFP/revision/trackhubs/data/barcodes/"

# cellranger directory:
cellranger_dir="/dfs7/swaruplab/smorabit/collab/woodlab/cocaine_mouse_2021/data/cellranger/"

# directory where we will output bam files:
output_dir="/dfs7/swaruplab/smorabit/collab/woodlab/cocaine_mouse_2021/Nurr2c_vs_GFP/revision/trackhubs/data/bams/"

# mkdir -p $output_dir/celltypes
# mkdir -p $output_dir/clusters

# get current sample based on the SLURM job ID
let index="$SLURM_ARRAY_TASK_ID"
samples=($(ls $barcodes_dir))
file=${samples[$index]}
echo $file
if [[ "$file" == "Wood"* ]]; then
  sample_name=($(echo $file | cut -d '_' -f 1-3))
  sample=($(echo $file | cut -d '_' -f 1-4))
else 
  sample_name=($(echo $file | cut -d '_' -f 1))
  sample=($(echo $file | cut -d '_' -f 1-2))
fi 

echo $sample
echo $sample_name

# make output folders for this sample:
mkdir $output_dir/$sample

################################################################################
# sinto processing
################################################################################

# run sinto to split .bam file by barcodes
cd $output_dir/$sample

sinto filterbarcodes \
  -b $cellranger_dir/$sample_name/"outs/possorted_genome_bam.bam" \
  -c $barcodes_dir/$sample"_barcodes.tsv" \
  -p  32 # number of processors

# index all of the bam files in this folder:
for f in *; do
  samtools index -@ 32 $f
done
